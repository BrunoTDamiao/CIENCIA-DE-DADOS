{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0dc0b55-a31e-4bfa-8f02-37be52f89182",
   "metadata": {},
   "source": [
    "### Tarefa 1 \n",
    "1. Monte um passo a passo para o Bagging\n",
    "2. Explique com suas palavras o Bagging\n",
    "3. (Opcional) Implementar em python o código do Bagging– Bootstrap– Modelagem– Agregação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758ff4e-cf34-440f-bc52-8887e870c875",
   "metadata": {},
   "source": [
    "## Passo a Passo para Implementar o Bagging:\n",
    "\n",
    "1. Coletar e Preparar os Dados\n",
    "> - Recolher os dados e dividir entre features e target, depois fazer um pré-procesamento, como normalização, tratamento de dados, remoção de outlier e então dividir os dados em treino e teste para garantir que a avaliação do modelo seja feito corretamente.\n",
    "\n",
    "2. Gerar Amostras Bootstrap\n",
    "> -  gerar amostrar co substituição a partir do conjunto de treino original.Cada amostra vai ter o esmo tamanho que o conjunto original, contendo exemplos repetidos e excluindo alguns. As amostras são usadas para treinar diferentes modelos.\n",
    "\n",
    "3. Treinar um Modelo em Cada Amostra Bootstrap\n",
    "> - para cara amostra bootstrap, treine um modelo independente, o mais comum para Bagging é uma Decision Tree. Mas, qualquer modelo supervisionado pode ser usado. Treinando cada modelo em uma amostra diferente, os modelos irão capturar diferentes aspetos dos dados, assim, ajudando a reduzir a variância.\n",
    "\n",
    "\n",
    "4. Realizar a Previsão de Cada Modelo\n",
    "> -  Aplicar cada modelo treinado para fazer previsões no conjunto de teste. Cada ponto de dado no conjunto de tete, cada modelo irá gerar uma previsão\n",
    "\n",
    "5. Combinar as Previsões (Votação ou Média)\n",
    "> - Para problemas de classificação, usamos a votação por maioria A classe que for mais comum entre as previsões dos modelos será a classe final.\n",
    "    >> - Ex: se 3 de 5 modelos prevee a classe \"A\" e 2 preveem a classe \"B\", a previsão final será \"A\".\n",
    "> - Para problemas de regressão, tiramos a média das previsões feitas pelos diferentes modelos.\n",
    "    >> - Ex: Se os modelos prevee os valores [10.5, 9.8, 11.0], a previsão final sera a média desses valores: (10.5 + 9.8 + 11.0) / 3.\n",
    "\n",
    "6. Avaliar o Desempenho do Modelo Bagging\n",
    "> - Calcular métricas de desempenho no conjunto de teste, como como acurácia, precisão, recall (para classificação) ou erro quadrático médio (para regressão). Comparar o desempenho do modelo **bagging* com o de um modelo sem **bagging** para verificar o quanto a variância for reduzida e se a precisão foi aumentada.\n",
    "\n",
    "7. Ajustar Parâmetros e Testar Melhorias\n",
    "> - Número de modelos: Pdoemos experimentar diferentes quantidades de amostras bootstrap. Mais modelos podem aumentar a estabilidade e precisão, mas também aumenta o custo computacional.\n",
    "> - Tamanho das amostras: em vez de usar o mesmo tamanho da amostra original, pode variar o tamanho da amostra bootstrap.\n",
    "> - Hiperparâmetros dos modelos base: Podemos ajustar os hiperparâmetros dos modelos usados em cada amostra, como a profundidade máxima das Decision Tree, número minimo de amostras por nó, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec70c3-77de-48d8-b6ef-74009624eebb",
   "metadata": {},
   "source": [
    "## Explique com suas palavras o Bagging\n",
    "\n",
    "> - O **Bagging** é usado para redução de Overfitting, Aumento da precisão e estabilidade de modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eccecd-40c8-4e94-8712-7ba2f345a0ff",
   "metadata": {},
   "source": [
    "## Implementar em python o código do Bagging– Bootstrap– Modelagem– Agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9197f7a5-066f-47ad-a3e6-1857a028ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d51d2550-355e-44c8-bab1-84ab5ae5dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dfc2695-3ad5-43e0-a595-ae1bb45b0e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(X, y):\n",
    "    n_samples = X.shape[0]\n",
    "    indices = np.random.choice(n_samples, size=n_samples, replace=True)  # Com substituição\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "def train_bagging_model(X_train, y_train, n_estimators=10):\n",
    "    models = []\n",
    "    for _ in range(n_estimators):\n",
    "        X_sample, y_sample = bootstrap_sample(X_train, y_train)  # Gerar amostra bootstrap\n",
    "        model = DecisionTreeClassifier()  # Modelo base: Árvore de Decisão\n",
    "        model.fit(X_sample, y_sample)  # Treinar o modelo com a amostra\n",
    "        models.append(model)  # Armazenar o modelo treinado\n",
    "    return models\n",
    "\n",
    "def bagging_predict(models, X_test):\n",
    "    # Cada modelo faz uma previsão\n",
    "    predictions = np.array([model.predict(X_test) for model in models])\n",
    "    \n",
    "    # Votação por maioria: escolhemos a classe mais votada por cada modelo\n",
    "    majority_votes = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
    "    return majority_votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d7f48ab-2b3e-4b02-9d5c-1d3ddf74dd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Bagging: 95.91%\n"
     ]
    }
   ],
   "source": [
    "# Treinar múltiplos modelos usando Bagging\n",
    "n_estimators = 100  # Número de árvores (modelos) que queremos treinar\n",
    "models = train_bagging_model(X_train, y_train, n_estimators)\n",
    "\n",
    "# Fazer previsões no conjunto de teste usando o modelo Bagging\n",
    "y_pred = bagging_predict(models, X_test)\n",
    "\n",
    "# Avaliar a acurácia do modelo Bagging\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo Bagging: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05dd309-008e-4641-b8b5-6d273a6be29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
